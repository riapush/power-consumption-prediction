{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDV6gkLfRQFE"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_10_3_transformer_timeseries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCN5sMiPLKF0",
        "outputId": "66c38143-3e65-4f70-f1e7-bd912858b53a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: not using Google CoLab\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
        "import torch\n",
        "has_mps = torch.backends.mps.is_built()\n",
        "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1kJpAnpQ8vcz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RvQ6vUqbE6r6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = pd.read_csv('data_with_weather_wo_outliers.csv')\n",
        "X = X.set_index('Date')\n",
        "X.index = pd.to_datetime(X.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE0PP-lpNUB-"
      },
      "source": [
        "The data preprocessing is the same as was introduced in the previous section. We will use data before the year 2000 as training, the rest is used for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "us_X4qz3NVh9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test  = train_test_split(X, test_size=0.2, shuffle=False)\n",
        "\n",
        "y_train = X_train['total_demand'].to_numpy().reshape(-1, 1)\n",
        "y_test = X_test['total_demand'].to_numpy().reshape(-1, 1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "y_train = scaler.fit_transform(y_train).flatten().tolist()\n",
        "y_test = scaler.transform(y_test).flatten().tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvZXHfkGTPX6"
      },
      "source": [
        "Just like we did for LSTM in the previous section, we again break the data into sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9utrJg62N1P-"
      },
      "outputs": [],
      "source": [
        "# Sequence Data Preparation\n",
        "SEQUENCE_SIZE = 10\n",
        "\n",
        "def to_sequences(seq_size, obs):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(obs) - seq_size):\n",
        "        window = obs[i:(i + seq_size)]\n",
        "        after_window = obs[i + seq_size]\n",
        "        x.append(window)\n",
        "        y.append(after_window)\n",
        "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "x_train, y_train = to_sequences(SEQUENCE_SIZE, y_train)\n",
        "x_test, y_test = to_sequences(SEQUENCE_SIZE, y_test)\n",
        "\n",
        "# Setup data loaders for batch\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wi-bRiyCN7Cw"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding for Transformer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR-CJLeOzpd"
      },
      "source": [
        "# Constructing the Transformer Model\n",
        "\n",
        "The following code constructs the actual transformer-based model for time series prediction. The model is constructed to accept the following parameters.\n",
        "\n",
        "* **input_dim**: The dimension of the input data, in this case we use only one input, the number of sunspots.\n",
        "* **d_model**: The number of features in the transformer model's internal representations (also the size of embeddings). This controls how much a model can remember and process.\n",
        "* **nhead**: The number of attention heads in the multi-head self-attention mechanism.\n",
        "* **num_layers**: The number of transformer encoder layers.\n",
        "dropout: The dropout probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hoT-VFSdOANz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Valer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "# Model definition using Transformer\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=3, dropout=0.3):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.decoder = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.decoder(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "model = TransformerModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjsuijqZ-bf7",
        "outputId": "b02a3cf7-7a98-4a00-befc-0eeb08063c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TransformerModel(\n",
            "  (encoder): Linear(in_features=1, out_features=64, bias=True)\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
            "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8-mF1OCOLnB",
        "outputId": "4ec14187-ca0a-48f3-e618-0ef0bc7ef589"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
            "File \u001b[1;32mc:\\Users\\Valer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Valer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "all_train = []\n",
        "all_valid = []\n",
        "# Train the model\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "early_stop_count = 0\n",
        "min_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for batch in train_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    train_loss = np.mean(train_losses)\n",
        "    all_train.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    val_mae = 0\n",
        "    val_mape = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            x_batch, y_batch = batch\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_losses.append(loss.item())\n",
        "\n",
        "    val_loss = np.mean(val_losses)\n",
        "    all_valid.append(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        early_stop_count = 0\n",
        "    else:\n",
        "        early_stop_count += 1\n",
        "\n",
        "    # if early_stop_count >= 5:\n",
        "    #     print(\"Early stopping!\")\n",
        "    #     break\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, loss: {train_loss}, val_loss: {val_loss}\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(all_train) + 1), all_train, label='Train Loss')\n",
        "plt.plot(range(1, len(all_valid) + 1), all_valid, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS-lkHvOhXGm"
      },
      "source": [
        "We can now evaluate the performance of this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE9fco0GOQr6",
        "outputId": "af03c97d-cbdd-4fd1-a93e-b6d405754728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score (MAPE): 0.0145\n",
            "Score (MAE): 2.7557\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch = x_batch.to(device)\n",
        "        outputs = model(x_batch)\n",
        "        predictions.extend(outputs.squeeze().tolist())\n",
        "\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "mape = mean_absolute_percentage_error(scaler.inverse_transform(np.array(predictions).reshape(-1, 1)), scaler.inverse_transform(y_test.numpy().reshape(-1, 1)))\n",
        "mae = mean_absolute_error(scaler.inverse_transform(np.array(predictions).reshape(-1, 1)), scaler.inverse_transform(y_test.numpy().reshape(-1, 1)))\n",
        "print(f\"Score (MAPE): {mape:.4f}\")\n",
        "print(f\"Score (MAE): {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformers'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m      2\u001b[0m model_bert \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprajjwal1/bert-tiny\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "model_bert = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
            "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 43.8/43.8 kB 1.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.2)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in c:\\users\\valer\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\valer\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\valer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\valer\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2023.7.22)\n",
            "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.2/9.1 MB 5.3 MB/s eta 0:00:02\n",
            "   - -------------------------------------- 0.5/9.1 MB 5.6 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.9/9.1 MB 7.3 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 1.4/9.1 MB 8.0 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.4/9.1 MB 8.0 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 2.3/9.1 MB 8.0 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 2.9/9.1 MB 9.8 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 3.3/9.1 MB 9.2 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 4.3/9.1 MB 10.2 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 4.9/9.1 MB 10.4 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 5.4/9.1 MB 10.5 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 6.0/9.1 MB 10.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 6.5/9.1 MB 10.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 7.1/9.1 MB 10.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 7.6/9.1 MB 10.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 8.2/9.1 MB 10.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 8.7/9.1 MB 11.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.1/9.1 MB 11.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.1/9.1 MB 10.4 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
            "   ---------------------------------------- 0.0/401.7 kB ? eta -:--:--\n",
            "   --------------------------------------  399.4/401.7 kB 25.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 401.7/401.7 kB 8.3 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
            "   ---------------------------------------- 0.0/287.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 287.4/287.4 kB 8.7 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.5/2.2 MB 14.9 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.0/2.2 MB 13.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 12.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.2/2.2 MB 11.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 10.9 MB/s eta 0:00:00\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.23.2 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
